{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i5afvUbhmGo"
      },
      "source": [
        "---\n",
        "\n",
        "# University of Liverpool\n",
        "\n",
        "## COMP534 - Applied AI\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpEqsZpRKtkE"
      },
      "source": [
        "This notebook is associated with Assignment 2. Use it to complete the assignment by following the instructions provided in each section. Each section includes a text cell outlining the requirements. For additional details, refer to Canvas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yE_QM-Rh9ngx"
      },
      "source": [
        "If you are using Google Colab, you can use the cell below to download and unzip the data.\n",
        "If you are running on your computer, you will need to do this yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2LzMK0nmmwv"
      },
      "outputs": [],
      "source": [
        "!wget http://weegee.vision.ucmerced.edu/datasets/UCMerced_LandUse.zip\n",
        "!unzip UCMerced_LandUse.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwGBUHRSKvf1"
      },
      "source": [
        "Use this first cell to import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "taBOSk4HKwZp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\maddy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import transforms\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hglJVRRslqMn"
      },
      "source": [
        "# 1. **Data Management**\n",
        "\n",
        "\n",
        "In this part, you need to:\n",
        "\n",
        "1.  define your experimental protocol (such as k-fold, cross validation, etc)\n",
        "2.\tcreate the dataloader to load the data; remember to include here any normalization, data augmentation, or other technique used to pre-process the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szQFlMDMJYEh"
      },
      "outputs": [],
      "source": [
        "# Write your proposed solution code here. Create more code cells if you find it necessary\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transformations (normalization and augmentation)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScTrpUW8zOp4"
      },
      "source": [
        "---\n",
        "\n",
        "# 2. **Neural Networks**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tpropose your own Convolutional Neural Network (CNN) to tackle the problem;\n",
        "2.\tdefine at least one existing CNN (such as AlexNet, VGG, ResNet, DenseNet, etc) to tackle the problem;\n",
        "3.\tdefine the necessary components to train the networks (that is, loss function, optimizers, etc);\n",
        "4.\ttrain your proposed architecture from scratch using your training set;\n",
        "5.\ttrain the existing architecture using at least 2 different strategies (i.e., trained from scratch, fine-tuning, feature extractor, etc);\n",
        "6.\tfor all training procedures, separately plot the loss and accuracy with respect to the epoch/iteration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJs8HpW_zX0M"
      },
      "outputs": [],
      "source": [
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs=10):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        # Compute average training loss and accuracy\n",
        "        epoch_train_loss = running_loss / len(train_loader)\n",
        "        epoch_train_acc = 100 * correct_train / total_train\n",
        "        train_losses.append(epoch_train_loss)\n",
        "        train_accuracies.append(epoch_train_acc)\n",
        "\n",
        "        # Evaluation phase\n",
        "        model.eval()\n",
        "        running_test_loss = 0.0\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_test_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_test += (predicted == labels).sum().item()\n",
        "                total_test += labels.size(0)\n",
        "\n",
        "        # Compute average test loss and accuracy\n",
        "        epoch_test_loss = running_test_loss / len(test_loader)\n",
        "        epoch_test_acc = 100 * correct_test / total_test\n",
        "        test_losses.append(epoch_test_loss)\n",
        "        test_accuracies.append(epoch_test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}% | \"\n",
        "              f\"Test Loss: {epoch_test_loss:.4f}, Test Acc: {epoch_test_acc:.2f}%\")\n",
        "\n",
        "    return train_losses, test_losses, train_accuracies, test_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RBW58of0ZDo"
      },
      "source": [
        "---\n",
        "\n",
        "# 3. **Evaluate models**\n",
        "\n",
        "Here, you need to:\n",
        "\n",
        "1.\tevaluate the model (the best one you obtained in the above stage) on the testing dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHWwdXg32BEl"
      },
      "outputs": [],
      "source": [
        "# Write your proposed solution code here. Create more code cells if you find it necessary\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
